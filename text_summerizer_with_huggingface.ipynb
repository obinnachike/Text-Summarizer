{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8qCSLXdK8dbmMjkUifYqd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obinnachike/Text-Summarizer/blob/main/text_summerizer_with_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG7flfqK2RNN"
      },
      "outputs": [],
      "source": [
        "!invidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rough_score py7zr -q"
      ],
      "metadata": {
        "id": "ICBw1cSs261Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "sRCgg_gz3JFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from datasets import load_dataset, load_from_disk, load_metric\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForSeq2seqLM, AutoTokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "ehP8MSvo3rfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "FqD0iAzI4xuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrianed(model_ckpt)"
      ],
      "metadata": {
        "id": "xQN11EgR5C69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "pgJ_qAyD50mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum = load_dataset(\"samsum\")"
      ],
      "metadata": {
        "id": "lefN8Ql56O0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum"
      ],
      "metadata": {
        "id": "rvEc_Tw57b5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train']['dialogue'][1]"
      ],
      "metadata": {
        "id": "tFWBMqrC7gs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train'][1]['summary']"
      ],
      "metadata": {
        "id": "voGJNTy376QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
        "\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
        "print(\"\\nDialogue\")\n",
        "\n",
        "print(dataset_samsum['test'][1][\"dialogue\"])\n",
        "\n",
        "print(\"\\nSummary\")\n",
        "print(dataset_samsum['test'][1][\"summary\"])"
      ],
      "metadata": {
        "id": "WFlBvHuG8Go0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "  input_encodings = tokenizer(example_batch['dialogue'], max_length = 1024, truncation = True)\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True)\n",
        "\n",
        "  return {\n",
        "      'input_ids' : input_encodings['input_ids'],\n",
        "      'attention_mask' : input_encodings['attention_mask']\n",
        "      'labels' : target_encodings['input_ids']\n",
        "  }"
      ],
      "metadata": {
        "id": "tAA4uvzEAXBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"
      ],
      "metadata": {
        "id": "LT3vg03RCNWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']"
      ],
      "metadata": {
        "id": "wDauUxnVCv1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']['input_ids'][1]"
      ],
      "metadata": {
        "id": "40GIrwShC39I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model = model_pegasus)"
      ],
      "metadata": {
        "id": "_oNwCh0FDPBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguements(\n",
        "    output_dir = \"pegasus-samsum\",   #Output directory\n",
        "    warmup_steps = 500,\n",
        "    eval_strategy = \"steps\",   #Evaluate every epoch\n",
        "    eval_steps = 500,\n",
        "    save_steps = 1e6,\n",
        "    learning_rate = 2e-5, # learning rate\n",
        "    per_device_train_batch_size = 1, #Batch size for training\n",
        "    per_device_eval_batch_size = 1, #Batch size for evaluation\n",
        "    num_train_epochs = 1, #Number of training Epochs\n",
        "    weight_decay = 0.01, # Strenght of weight decay\n",
        "    logging_steps = 10,\n",
        "    gradient_accumulation_steps = 16\n",
        ")"
      ],
      "metadata": {
        "id": "hhDs0eNhDofi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model_pegasus,\n",
        "    args = training_args,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = seq2seq_data_collator,\n",
        "    train_dataset = tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized-datasets[\"test\"]\n",
        ")"
      ],
      "metadata": {
        "id": "g3C-ZyFWFLaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "raLx1UzPF522"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}